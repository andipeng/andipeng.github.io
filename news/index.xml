<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>News | Andi Peng</title>
    <link>https://andipeng.github.io/news/</link>
      <atom:link href="https://andipeng.github.io/news/index.xml" rel="self" type="application/rss+xml" />
    <description>News</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2024</copyright><lastBuildDate>Fri, 01 Dec 2017 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://andipeng.github.io/img/icon-192.png</url>
      <title>News</title>
      <link>https://andipeng.github.io/news/</link>
    </image>
    
    <item>
      <title>News</title>
      <link>https://andipeng.github.io/news/news/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/news/news/</guid>
      <description>








&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2024]&lt;/span&gt;&lt;/strong&gt; I am giving a talk at the MILA Robot Learning Seminar.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2024]&lt;/span&gt;&lt;/strong&gt; I will be visiting Constellation, an AI safety research center, for two weeks!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jan 2024]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/abs/2402.18759&#34;&gt;Learning with Language-Guided State Abstractions&lt;/a&gt; was accepted to ICLR 2024.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Dec 2023]&lt;/span&gt;&lt;/strong&gt; Attending NeurIPS! I&amp;rsquo;m presenting &lt;a href=&#34;https://arxiv.org/abs/2310.17550&#34;&gt;Human-Guided Complexity-Controlled Abstractions&lt;/a&gt; in the main conference and co-organizing the &lt;a href=&#34;https://goal-conditioned-rl.github.io/&#34;&gt;Goal-Conditioned Reinforcement Learning Workshop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Nov 2023]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/abs/2307.15217&#34;&gt;Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback&lt;/a&gt; was accepted to TMLR.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Nov 2023]&lt;/span&gt;&lt;/strong&gt; Our papers &lt;a href=&#34;https://arxiv.org/abs/2302.01928&#34;&gt;Aligning Human and Robot Representations&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2402.03081&#34;&gt;Preference-Conditioned Language-Guided Abstraction&lt;/a&gt; were accepted to HRI 2024.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Nov 2023]&lt;/span&gt;&lt;/strong&gt; Our new preprint &lt;a href=&#34;https://arxiv.org/abs/2310.13018&#34;&gt;Getting Aligned on Representational Alignment&lt;/a&gt; is out.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Nov 2023]&lt;/span&gt;&lt;/strong&gt; I passed my quals at MIT!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Sep 2023]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/abs/2310.17550&#34;&gt;Human-Guided Complexity-Controlled Abstractions&lt;/a&gt; was accepted to NeurIPS 2023.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Sep 2023]&lt;/span&gt;&lt;/strong&gt; I started my internship at the Boston Dynamics AI Institute!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jul 2023]&lt;/span&gt;&lt;/strong&gt; I gave an interview for &lt;a href=&#34;https://twitter.com/MichaelTrazzi/status/1688935598370021377&#34;&gt;The Inside View&lt;/a&gt; at ICML!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jul 2023]&lt;/span&gt;&lt;/strong&gt; Attending ICML! I&amp;rsquo;m presenting &lt;a href=&#34;https://arxiv.org/abs/2307.06333&#34;&gt;Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation&lt;/a&gt; in the main conference and co-organizing the &lt;a href=&#34;https://interactive-learning-implicit-feedback.github.io/&#34;&gt;Interactive Learning from Implicit Human Feedback Workshop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jun 2023]&lt;/span&gt;&lt;/strong&gt; I started my internship at the MIT-IBM Watson AI Lab.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[May 2023]&lt;/span&gt;&lt;/strong&gt; I spoke alongside Congressman Bill Foster at the &lt;a href=&#34;https://insights-north-america.aon.com/technology-communications/risk-perspectives-on-artificial-intelligence-video&#34;&gt;Aon AI Fireside Chat&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[May 2023]&lt;/span&gt;&lt;/strong&gt; I gave a talk at the Yale for Humanity event on &lt;a href=&#34;https://forhumanity.yale.edu/events/fhi-chicago&#34;&gt;Artificial Intelligence, Ethics, and Society: Utilizing Technology for Good&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Apr 2023]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/abs/2307.06333&#34;&gt;Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation&lt;/a&gt; was accepted to ICML 2023.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Apr 2023]&lt;/span&gt;&lt;/strong&gt; I ran the Boston Marathon!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2023]&lt;/span&gt;&lt;/strong&gt; I was awarded a fellowship from Open Philanthropy!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2023]&lt;/span&gt;&lt;/strong&gt; I received my M.S. from MIT EECS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Dec 2022]&lt;/span&gt;&lt;/strong&gt; I co-organized the &lt;a href=&#34;https://aligning-robot-human-representations.github.io/&#34;&gt;Aligning Robot Representations with Humans&lt;/a&gt; workshop at CoRL 2022.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Dec 2022]&lt;/span&gt;&lt;/strong&gt; I presented two workshop papers at NeurIPS 2022.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jul 2022]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://www.nature.com/articles/d41586-022-02033-y&#34;&gt;Make greenhouse-gas accounting reliable â€” build interoperable systems&lt;/a&gt; was published in &lt;em&gt;Nature&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2022]&lt;/span&gt;&lt;/strong&gt; I presented &lt;a href=&#34;https://arxiv.org/abs/2202.11812&#34;&gt;Investigations of Performance and Bias in Human-AI Teamwork in Hiring&lt;/a&gt; as an oral presentation at AAAI 2022.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[May 2021]&lt;/span&gt;&lt;/strong&gt; I started my internship at FAIR.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Sep 2020]&lt;/span&gt;&lt;/strong&gt; I started my PhD at MIT advised by &lt;a href=&#34;https://people.csail.mit.edu/pulkitag/&#34;&gt;Pulkit Agrawal&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Apr 2022]&lt;/span&gt;&lt;/strong&gt; I was awarded the NSF GRFP fellowship.&lt;/p&gt;

</description>
    </item>
    
  </channel>
</rss>
