**<span style="color:orange">[May 2024]</span>** I started at Anthropic for the summer! I'll be working to help make models safer.

**<span style="color:orange">[May 2024]</span>** Attending ICLR! I'll be presenting [LGA](https://arxiv.org/pdf/2402.18759.pdf) in the main conference and [PLGA](https://arxiv.org/pdf/2402.03081.pdf) in the [LLM Agents Workshop](https://llmagents.github.io/). I'll also be a panelist in the [Representational Alignment Workshop](https://representational-alignment.github.io/).

**<span style="color:orange">[Apr 2024]</span>** I ran the Boston Marathon!

**<span style="color:orange">[Mar 2024]</span>** Attending HRI! Our papers [Aligning Human and Robot Representations](https://arxiv.org/pdf/2302.01928.pdf) and [Preference-Conditioned Language-Guided Abstraction](https://arxiv.org/pdf/2402.03081.pdf) will be presented in the main conference.

**<span style="color:orange">[Feb 2024]</span>** I am giving talks at the [MILA Robot Learning Seminar](https://www.youtube.com/watch?v=rHkhSdEUJTA&ab_channel=MontrealRobotics) and UC Berkeley.

**<span style="color:orange">[Feb 2024]</span>** I will be visiting Constellation, an AI safety research center, for two weeks!

**<span style="color:orange">[Jan 2024]</span>** Our paper [Learning with Language-Guided State Abstractions](https://arxiv.org/abs/2402.18759) was accepted to ICLR 2024.

**<span style="color:orange">[Dec 2023]</span>** Attending NeurIPS! I'm presenting [Human-Guided Complexity-Controlled Abstractions](https://arxiv.org/abs/2310.17550) in the main conference and co-organizing the [Goal-Conditioned Reinforcement Learning Workshop](https://goal-conditioned-rl.github.io/).

**<span style="color:orange">[Nov 2023]</span>** Our paper [Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2307.15217) was accepted to TMLR.

**<span style="color:orange">[Nov 2023]</span>** Our papers [Aligning Human and Robot Representations](https://arxiv.org/abs/2302.01928) and [Preference-Conditioned Language-Guided Abstraction](https://arxiv.org/abs/2402.03081) were accepted to HRI 2024.

**<span style="color:orange">[Nov 2023]</span>** Our new preprint [Getting Aligned on Representational Alignment](https://arxiv.org/abs/2310.13018) is out.

**<span style="color:orange">[Nov 2023]</span>** I passed my quals at MIT!

**<span style="color:orange">[Sep 2023]</span>** Our paper [Human-Guided Complexity-Controlled Abstractions](https://arxiv.org/abs/2310.17550) was accepted to NeurIPS 2023.

**<span style="color:orange">[Sep 2023]</span>** I started my internship at the Boston Dynamics AI Institute!

**<span style="color:orange">[Jul 2023]</span>** I gave an interview for [The Inside View](https://twitter.com/MichaelTrazzi/status/1688935598370021377) at ICML!

**<span style="color:orange">[Jul 2023]</span>** Attending ICML! I'm presenting [Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation](https://arxiv.org/abs/2307.06333) in the main conference and co-organizing the [Interactive Learning from Implicit Human Feedback Workshop](https://interactive-learning-implicit-feedback.github.io/).

**<span style="color:orange">[Jun 2023]</span>** I started my internship at the MIT-IBM Watson AI Lab.

**<span style="color:orange">[May 2023]</span>** I spoke alongside Congressman Bill Foster at the [Aon AI Fireside Chat](https://insights-north-america.aon.com/technology-communications/risk-perspectives-on-artificial-intelligence-video).

**<span style="color:orange">[May 2023]</span>** I gave a talk at the Yale for Humanity event on [Artificial Intelligence, Ethics, and Society: Utilizing Technology for Good](https://forhumanity.yale.edu/events/fhi-chicago).

**<span style="color:orange">[Apr 2023]</span>** Our paper [Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation](https://arxiv.org/abs/2307.06333) was accepted to ICML 2023.

**<span style="color:orange">[Apr 2023]</span>** I ran the Boston Marathon!

**<span style="color:orange">[Feb 2023]</span>** I was awarded a fellowship from Open Philanthropy!

**<span style="color:orange">[Feb 2023]</span>** I received my M.S. from MIT EECS.

**<span style="color:orange">[Dec 2022]</span>** I co-organized the [Aligning Robot Representations with Humans](https://aligning-robot-human-representations.github.io/) workshop at CoRL 2022.

**<span style="color:orange">[Dec 2022]</span>** I presented two workshop papers at NeurIPS 2022.

**<span style="color:orange">[Jul 2022]</span>** Our paper [Make greenhouse-gas accounting reliable â€” build interoperable systems](https://www.nature.com/articles/d41586-022-02033-y) was published in *Nature*.

**<span style="color:orange">[Feb 2022]</span>** I presented [Investigations of Performance and Bias in Human-AI Teamwork in Hiring](https://arxiv.org/abs/2202.11812) as an oral presentation at AAAI 2022.

**<span style="color:orange">[May 2021]</span>** I started my internship at FAIR.

**<span style="color:orange">[Sep 2020]</span>** I started my PhD at MIT advised by [Pulkit Agrawal](https://people.csail.mit.edu/pulkitag/).

**<span style="color:orange">[Apr 2022]</span>** I was awarded the NSF GRFP fellowship.