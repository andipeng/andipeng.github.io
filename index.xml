<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Andi Peng</title>
    <link>https://andipeng.github.io/</link>
      <atom:link href="https://andipeng.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Andi Peng</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2024</copyright><lastBuildDate>Sat, 08 Jun 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://andipeng.github.io/img/icon-192.png</url>
      <title>Andi Peng</title>
      <link>https://andipeng.github.io/</link>
    </image>
    
    <item>
      <title>Adaptive Language-Guided Abstraction from Contrastive Explanations</title>
      <link>https://andipeng.github.io/publication/2024-corl-algae/</link>
      <pubDate>Sat, 08 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2024-corl-algae/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Constrained Human-AI: An Inclusive Embodied AI Assistance Challenge</title>
      <link>https://andipeng.github.io/publication/2024-neurips-constrained/</link>
      <pubDate>Sun, 19 May 2024 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2024-neurips-constrained/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from Human Feedback</title>
      <link>https://andipeng.github.io/publication/2024-icml-featprefs/</link>
      <pubDate>Tue, 30 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2024-icml-featprefs/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning with Language-Guided State Abstractions</title>
      <link>https://andipeng.github.io/publication/2024-iclr-lga/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2024-iclr-lga/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Aligning Robot Representations with Humans</title>
      <link>https://andipeng.github.io/publication/2024-hri-aligning/</link>
      <pubDate>Thu, 30 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2024-hri-aligning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Preference-Conditioned Language-Guided Abstractions</title>
      <link>https://andipeng.github.io/publication/2024-hri-plga/</link>
      <pubDate>Thu, 30 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2024-hri-plga/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Getting Aligned on Representational Alignment</title>
      <link>https://andipeng.github.io/publication/2023-preprint-repalign/</link>
      <pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2023-preprint-repalign/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Human-Guided Complexity-Controlled Abstractions</title>
      <link>https://andipeng.github.io/publication/2023-neurips-complexity/</link>
      <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2023-neurips-complexity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback</title>
      <link>https://andipeng.github.io/publication/2023-tmlr-rlhf/</link>
      <pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2023-tmlr-rlhf/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation</title>
      <link>https://andipeng.github.io/publication/2023-icml-counterfactuals/</link>
      <pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2023-icml-counterfactuals/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Strengthening Subcommunities: Towards Sustainable Growth in AI Research</title>
      <link>https://andipeng.github.io/publication/2022-iclrworkshop-mlevaluation/</link>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2022-iclrworkshop-mlevaluation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Make Greenhouse-Gas Accounting Reliable — Build Interoperable Systems</title>
      <link>https://andipeng.github.io/publication/2022-nature-climate/</link>
      <pubDate>Tue, 12 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2022-nature-climate/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigations of Performance and Bias in Human-AI Teamwork in Hiring</title>
      <link>https://andipeng.github.io/publication/2022-aaai-hiring/</link>
      <pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2022-aaai-hiring/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On the Nature of Bias Percolation: Assessing Multiaxial Collaboration in Human-AI Systems</title>
      <link>https://andipeng.github.io/publication/2020-chiworkshop-bias/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2020-chiworkshop-bias/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Human-Machine Collaboration for Fast Land Cover Mapping</title>
      <link>https://andipeng.github.io/publication/2020-aaai-landcover/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2020-aaai-landcover/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Perils of Objectivity: Towards a Normative Framework for Fair Judicial Decision-Making</title>
      <link>https://andipeng.github.io/publication/2020-aies-criminal/</link>
      <pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2020-aies-criminal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What You See Is What You Get? The Impact of Representation Criteria on Human Bias in Hiring</title>
      <link>https://andipeng.github.io/publication/2019-hcomp-hiring/</link>
      <pubDate>Mon, 28 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2019-hcomp-hiring/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Artificial Intelligence Research and Ethics Community Calls for Standards in Criminal Justice Risk Assessment Tools</title>
      <link>https://andipeng.github.io/post/partnership-on-ai-risk-assessment-report/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/post/partnership-on-ai-risk-assessment-report/</guid>
      <description></description>
    </item>
    
    <item>
      <title>My Journey to the Microsoft Research AI Residency</title>
      <link>https://andipeng.github.io/post/microsoft-ai-residency/</link>
      <pubDate>Mon, 10 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/post/microsoft-ai-residency/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Integrated Machine Learning Approach To Studying Terrorism</title>
      <link>https://andipeng.github.io/publication/2018-yale-thesis/</link>
      <pubDate>Fri, 20 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2018-yale-thesis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>News</title>
      <link>https://andipeng.github.io/news/news/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/news/news/</guid>
      <description>








&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Sep 2024]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/pdf/2409.08212&#34;&gt;Adaptive Language-Guided Abstraction from Contrastive Explanations&lt;/a&gt; was accepted to CoRL 2024.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Aug 2024]&lt;/span&gt;&lt;/strong&gt; I am taking leave from MIT to lead national security evaluations on the Frontier Red Team at Anthropic.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Aug 2024]&lt;/span&gt;&lt;/strong&gt; Attending RLC! I&amp;rsquo;ll be presenting Pragmatic Feature Preferences in the &lt;a href=&#34;https://rlbrew-workshop.github.io/&#34;&gt;RL Beyond Rewards Workshop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jul 2024]&lt;/span&gt;&lt;/strong&gt; Attending ICML! I&amp;rsquo;ll be presenting Pragmatic Feature Preferences in the main conference. I&amp;rsquo;ll also be attending the &lt;a href=&#34;https://www.alignment-workshop.com/&#34;&gt;Alignment Workshop&lt;/a&gt; beforehand.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jul 2024]&lt;/span&gt;&lt;/strong&gt; Attending RSS! I&amp;rsquo;m honored to be part of the &lt;a href=&#34;https://sites.google.com/view/rsspioneers2024/&#34;&gt;2024 RSS Pioneers&lt;/a&gt; cohort, as well as help organize the &lt;a href=&#34;https://social-intelligence-human-ai.github.io/proposal.html&#34;&gt;Social Intelligence in Humans and Robots Workshop&lt;/a&gt; and the &lt;a href=&#34;https://sites.google.com/view/rss-taskspec&#34;&gt;Task Specification Workshop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[May 2024]&lt;/span&gt;&lt;/strong&gt; I started at Anthropic! I&amp;rsquo;ll be working to help make big models safer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[May 2024]&lt;/span&gt;&lt;/strong&gt; Attending ICLR! I&amp;rsquo;ll be presenting &lt;a href=&#34;https://arxiv.org/pdf/2402.18759.pdf&#34;&gt;LGA&lt;/a&gt; in the main conference and &lt;a href=&#34;https://arxiv.org/pdf/2402.03081.pdf&#34;&gt;PLGA&lt;/a&gt; in the &lt;a href=&#34;https://llmagents.github.io/&#34;&gt;LLM Agents Workshop&lt;/a&gt;. I&amp;rsquo;ll also be a panelist in the &lt;a href=&#34;https://representational-alignment.github.io/&#34;&gt;Representational Alignment Workshop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Apr 2024]&lt;/span&gt;&lt;/strong&gt; I ran the Boston Marathon!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Mar 2024]&lt;/span&gt;&lt;/strong&gt; Attending HRI! Our papers &lt;a href=&#34;https://arxiv.org/pdf/2302.01928.pdf&#34;&gt;Aligning Human and Robot Representations&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/pdf/2402.03081.pdf&#34;&gt;Preference-Conditioned Language-Guided Abstraction&lt;/a&gt; will be presented in the main conference.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2024]&lt;/span&gt;&lt;/strong&gt; I am giving talks at the &lt;a href=&#34;https://www.youtube.com/watch?v=rHkhSdEUJTA&amp;amp;ab_channel=MontrealRobotics&#34;&gt;MILA Robot Learning Seminar&lt;/a&gt; and UC Berkeley.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2024]&lt;/span&gt;&lt;/strong&gt; I will be visiting Constellation, an AI safety research center, for two weeks!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jan 2024]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/abs/2402.18759&#34;&gt;Learning with Language-Guided State Abstractions&lt;/a&gt; was accepted to ICLR 2024.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Dec 2023]&lt;/span&gt;&lt;/strong&gt; Attending NeurIPS! I&amp;rsquo;m presenting &lt;a href=&#34;https://arxiv.org/abs/2310.17550&#34;&gt;Human-Guided Complexity-Controlled Abstractions&lt;/a&gt; in the main conference and co-organizing the &lt;a href=&#34;https://goal-conditioned-rl.github.io/&#34;&gt;Goal-Conditioned Reinforcement Learning Workshop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Nov 2023]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/abs/2307.15217&#34;&gt;Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback&lt;/a&gt; was accepted to TMLR.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Nov 2023]&lt;/span&gt;&lt;/strong&gt; Our papers &lt;a href=&#34;https://arxiv.org/abs/2302.01928&#34;&gt;Aligning Human and Robot Representations&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/2402.03081&#34;&gt;Preference-Conditioned Language-Guided Abstraction&lt;/a&gt; were accepted to HRI 2024.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Nov 2023]&lt;/span&gt;&lt;/strong&gt; Our new preprint &lt;a href=&#34;https://arxiv.org/abs/2310.13018&#34;&gt;Getting Aligned on Representational Alignment&lt;/a&gt; is out.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Nov 2023]&lt;/span&gt;&lt;/strong&gt; I passed my quals at MIT!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Sep 2023]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/abs/2310.17550&#34;&gt;Human-Guided Complexity-Controlled Abstractions&lt;/a&gt; was accepted to NeurIPS 2023.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Sep 2023]&lt;/span&gt;&lt;/strong&gt; I started my internship at the Boston Dynamics AI Institute!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jul 2023]&lt;/span&gt;&lt;/strong&gt; I gave an interview for &lt;a href=&#34;https://twitter.com/MichaelTrazzi/status/1688935598370021377&#34;&gt;The Inside View&lt;/a&gt; at ICML!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jul 2023]&lt;/span&gt;&lt;/strong&gt; Attending ICML! I&amp;rsquo;m presenting &lt;a href=&#34;https://arxiv.org/abs/2307.06333&#34;&gt;Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation&lt;/a&gt; in the main conference and co-organizing the &lt;a href=&#34;https://interactive-learning-implicit-feedback.github.io/&#34;&gt;Interactive Learning from Implicit Human Feedback Workshop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jun 2023]&lt;/span&gt;&lt;/strong&gt; I started my internship at the MIT-IBM Watson AI Lab.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[May 2023]&lt;/span&gt;&lt;/strong&gt; I spoke alongside Congressman Bill Foster at the &lt;a href=&#34;https://insights-north-america.aon.com/technology-communications/risk-perspectives-on-artificial-intelligence-video&#34;&gt;Aon AI Fireside Chat&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[May 2023]&lt;/span&gt;&lt;/strong&gt; I gave a talk at the Yale for Humanity event on &lt;a href=&#34;https://forhumanity.yale.edu/events/fhi-chicago&#34;&gt;Artificial Intelligence, Ethics, and Society: Utilizing Technology for Good&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Apr 2023]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://arxiv.org/abs/2307.06333&#34;&gt;Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation&lt;/a&gt; was accepted to ICML 2023.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Apr 2023]&lt;/span&gt;&lt;/strong&gt; I ran the Boston Marathon!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2023]&lt;/span&gt;&lt;/strong&gt; I was awarded a fellowship from Open Philanthropy!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2023]&lt;/span&gt;&lt;/strong&gt; I received my M.S. from MIT EECS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Dec 2022]&lt;/span&gt;&lt;/strong&gt; I co-organized the &lt;a href=&#34;https://aligning-robot-human-representations.github.io/&#34;&gt;Aligning Robot Representations with Humans&lt;/a&gt; workshop at CoRL 2022.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Dec 2022]&lt;/span&gt;&lt;/strong&gt; I presented two workshop papers at NeurIPS 2022.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Jul 2022]&lt;/span&gt;&lt;/strong&gt; Our paper &lt;a href=&#34;https://www.nature.com/articles/d41586-022-02033-y&#34;&gt;Make greenhouse-gas accounting reliable — build interoperable systems&lt;/a&gt; was published in &lt;em&gt;Nature&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Feb 2022]&lt;/span&gt;&lt;/strong&gt; I presented &lt;a href=&#34;https://arxiv.org/abs/2202.11812&#34;&gt;Investigations of Performance and Bias in Human-AI Teamwork in Hiring&lt;/a&gt; as an oral presentation at AAAI 2022.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[May 2021]&lt;/span&gt;&lt;/strong&gt; I started my internship at FAIR.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Sep 2020]&lt;/span&gt;&lt;/strong&gt; I started my PhD at MIT advised by &lt;a href=&#34;https://people.csail.mit.edu/pulkitag/&#34;&gt;Pulkit Agrawal&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&#34;color:orange&#34;&gt;[Apr 2022]&lt;/span&gt;&lt;/strong&gt; I was awarded the NSF GRFP fellowship.&lt;/p&gt;

</description>
    </item>
    
    <item>
      <title>Virgin Hyperloop One - Branson Boosts Elon Musk&#39;s Futuristic Tube Transport</title>
      <link>https://andipeng.github.io/post/hyperloop-forbes/</link>
      <pubDate>Thu, 12 Oct 2017 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/post/hyperloop-forbes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Faster, cheaper, cleaner - Experts disagree about Elon Musk&#39;s Hyperloop claims</title>
      <link>https://andipeng.github.io/post/hyperloop-the-guardian/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/post/hyperloop-the-guardian/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Three Yale students named Truman Scholars</title>
      <link>https://andipeng.github.io/post/truman-scholarship/</link>
      <pubDate>Mon, 17 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/post/truman-scholarship/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Conceptual Feasibility Study of the Hyperloop Vehicle for Next-Generation Transport</title>
      <link>https://andipeng.github.io/publication/2017-scitech-hyperloop/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2017-scitech-hyperloop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Early Detection of Boko Haram Attacks in Nigeria</title>
      <link>https://andipeng.github.io/publication/2017-jackson-capstone/</link>
      <pubDate>Wed, 21 Dec 2016 00:00:00 +0000</pubDate>
      <guid>https://andipeng.github.io/publication/2017-jackson-capstone/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
